""Importing dependencies""


import numpy as np 
import pandas as pd 
import os 
import matplotlib.pyplot as plt 
import tensorflow as tf 
from PIL import Image
import glob
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras import backend as K
from tensorflow import keras

*Loading and Splitting The Data*
images = []
mask = glob.glob("/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/*/*_mask.png")
for i in mask:
    images.append(i.replace('_mask',''))

print(images[:5])
print('-------------------')
print(mask[:5])

data = pd.DataFrame({'images':images,'masks':mask})
data.head(9)

data.shape

data_train,data_test=train_test_split(data,test_size=0.1)
data_train,data_val=train_test_split(data_train,test_size=0.1)

datagen = ImageDataGenerator(rotation_range=0.2,
                            width_shift_range=0.05,
                            height_shift_range=0.05,
                            shear_range=0.05,
                            zoom_range=0.05,
                            horizontal_flip=True,
                            fill_mode='nearest',
                            rescale=1./255)

image_train=datagen.flow_from_dataframe(data_train,  
                                    target_size=(512,512), 
                                    color_mode='rgb',
                                    shuffle=True,
                                    seed=123,
                                    x_col ="images", 
                                    batch_size=8,
                                    class_mode=None
                                        )
mask_train=datagen.flow_from_dataframe(data_train, 
                                    target_size=(512,512), 
                                    color_mode='grayscale',
                                    shuffle=True,
                                    seed=123,
                                    x_col ="masks", 
                                    batch_size=8,
                                    class_mode=None
)

image_validation=datagen.flow_from_dataframe(data_val,  
                                    target_size=(512,512), 
                                    color_mode='rgb',
                                    shuffle=True,
                                    seed=123,
                                    x_col ="images", 
                                    batch_size=8,
                                    class_mode=None
)

mask_validation=datagen.flow_from_dataframe(data_val, 
                                    target_size=(512,512), 
                                    color_mode='grayscale',
                                    shuffle=True,
                                    seed=123,
                                    x_col ="masks", 
                                    batch_size=8,
                                    class_mode=None
)


train_gen=zip(image_train,mask_train)
valid_gen=zip(image_validation,mask_validation)

from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input
from tensorflow.keras.models import Model
from tensorflow.keras.applications import ResNet50

def conv_block(inputs, num_filters):
    x = Conv2D(num_filters, 3, padding="same")(inputs)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    
    x = Conv2D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    
    return x


def decoder_block(inputs, skip_features, num_filters):
    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding="same")(inputs)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x


def build_resnet50_unet(input_shape):
    
    inputs = Input(input_shape)
    
    """Pre-trained ResNet50 Model"""
    resnet50 = ResNet50(include_top=False, weights="imagenet", input_tensor=inputs)
    
    """Encoder"""
    s1 = resnet50.get_layer("input_1").output #512
    s2 = resnet50.get_layer("conv1_relu").output #256
    s3 = resnet50.get_layer("conv2_block3_out").output #128
    s4 = resnet50.get_layer("conv3_block4_out").output #64
    
    """Bridge"""
    b1 = resnet50.get_layer("conv4_block6_out").output
    
    """Decoder"""
    d1 = decoder_block(b1, s4, 512) #64
    d2 = decoder_block(d1, s3, 256) #128
    d3 = decoder_block(d2, s2, 128) #256
    d4 = decoder_block(d3, s1, 64) #512
    
    """Outputs"""
    outputs = Conv2D(1, 1, padding="same", activation="sigmoid")(d4)
    
    model = Model(inputs, outputs)
 return model

model = build_resnet50_unet((512,512,3))

model.summary()


""Defining Metrics And Loss Functions""


import tensorflow as tf

def pixel_accuracy(y_true, y_pred):
    # Convert the predicted probabilities to class labels
    y_pred = tf.argmax(y_pred, axis=-1)

    # Flatten the tensors
    y_true = tf.reshape(y_true, [-1])
    y_pred = tf.reshape(y_pred, [-1])

    # Cast y_true to the same data type as y_pred
    y_true = tf.cast(y_true, y_pred.dtype)

    # Calculate the pixel accuracy
    correct_pixels = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))
    total_pixels = tf.cast(tf.size(y_true), tf.float32)

    accuracy = correct_pixels / total_pixels
    return accuracy

import tensorflow as tf
from keras import backend as K

def dice_coef(y_true, y_pred, smooth=1):
    y_true = tf.one_hot(K.argmax(y_true), 3)  
    y_pred = tf.one_hot(K.argmax(y_pred), 3)  
    intersection = K.sum(y_true * y_pred)
    union = K.sum(y_true) + K.sum(y_pred)
    dice_coef = (2.0 * intersection + smooth) / (union + smooth)
    return dice_coef


def dice_coef_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)


from tensorflow.keras.losses import categorical_crossentropy

def bce_dice_loss(y_true, y_pred):
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)

import tensorflow.keras as keras
keras.utils.get_custom_objects()['pixel_accuracy'] = pixel_accuracy
keras.utils.get_custom_objects()['dice_coef'] = dice_coef
keras.utils.get_custom_objects()['dice_coef_loss'] = dice_coef_loss
keras.utils.get_custom_objects()['bce_dice_loss'] = bce_dice_loss

""Training The Model""
model.compile(
    optimizer='adam',
    loss=bce_dice_loss,
    metrics=[dice_coef,'accuracy'])

history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=50,
    validation_steps=len(data_val) /8,
    steps_per_epoch=len(data_train) /8
)

eval_results = model.evaluate(valid_gen, steps=len(data_val) /32, verbose=1)

""Making Predictions""


import cv2
for i in range(10):
    index=np.random.randint(1,len(data_test.index))
    img = cv2.imread(data_test['images'].iloc[index])
    img = cv2.resize(img ,(256, 256))
    img = img / 255
    img = img[np.newaxis, :, :, :]
    pred=model.predict(img)

    plt.figure(figsize=(10,10))
    plt.subplot(1,4,1)
    plt.imshow(np.squeeze(img))
    plt.title('Original Image')
    plt.subplot(1,4,2)
    plt.imshow(np.squeeze(cv2.imread(data_test['masks'].iloc[index])))
    plt.title('Original Mask')
    plt.subplot(1,4,3)
    plt.imshow(np.squeeze(pred) > .8)
    plt.title('Prediction')
    plt.subplot(1,4,4)
    plt.imshow(np.squeeze(img))
    plt.imshow(np.squeeze(pred) > .8,alpha=0.4)
    plt.title('Image with prediction mask')
    plt.show()

""Saving The Model""

import pickle
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)
